{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.chdir('/Users/zhangle/tensorflow-without-a-phd/tensorflow-mnist-tutorial')\n",
    "import tensorflowvisu\n",
    "\n",
    "def batchnorm(Ylogits, is_test, iteration, offset, convolutional=False):\n",
    "    # adding the iteration prevents from averaging across non-existing iterations\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.999, iteration) \n",
    "    bnepsilon = 1e-5\n",
    "    if convolutional:\n",
    "        mean, variance = tf.nn.moments(Ylogits, [0, 1, 2])\n",
    "    else:\n",
    "        mean, variance = tf.nn.moments(Ylogits, [0])\n",
    "    update_moving_averages = exp_moving_avg.apply([mean, variance])\n",
    "    m = tf.cond(is_test, lambda: exp_moving_avg.average(mean), lambda: mean)\n",
    "    v = tf.cond(is_test, lambda: exp_moving_avg.average(variance), lambda: variance)\n",
    "    Ybn = tf.nn.batch_normalization(Ylogits, m, v, offset, None, bnepsilon)\n",
    "    return Ybn, update_moving_averages\n",
    "\n",
    "def no_batchnorm(Ylogits, is_test, iteration, offset, convolutional=False):\n",
    "    return Ylogits, tf.no_op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.read_stata('/Users/zhangle/Desktop/demo1.dta')\n",
    "d.head(2)\n",
    "\n",
    "# Normalization\n",
    "def Normalization(x):\n",
    "    return [(float(i)-min(x))/float(max(x)-min(x)) for i in x]\n",
    "# 归一化\n",
    "import numpy as np\n",
    "for i in [\"ages\",\"sbp\",\"dbp\",\"bmi\",\"tchol\",\"hdl\",\"glucosef\",\"duration1\"]:\n",
    "    d.ix[:,i]=Normalization(np.array(d.ix[:,i]))\n",
    "d.describe()\n",
    "\n",
    "X = d.ix[:,'ages':'duration1']\n",
    "Y = d.ix[:,'ep1_chdmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ages</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>bmi</th>\n",
       "      <th>tchol</th>\n",
       "      <th>hdl</th>\n",
       "      <th>glucosef</th>\n",
       "      <th>duration1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>1905.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.493845</td>\n",
       "      <td>0.371054</td>\n",
       "      <td>0.413667</td>\n",
       "      <td>0.270594</td>\n",
       "      <td>0.467650</td>\n",
       "      <td>0.313336</td>\n",
       "      <td>0.132905</td>\n",
       "      <td>0.638785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.148981</td>\n",
       "      <td>0.155093</td>\n",
       "      <td>0.146433</td>\n",
       "      <td>0.130686</td>\n",
       "      <td>0.150091</td>\n",
       "      <td>0.118098</td>\n",
       "      <td>0.074370</td>\n",
       "      <td>0.268002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.379982</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.184916</td>\n",
       "      <td>0.348271</td>\n",
       "      <td>0.227964</td>\n",
       "      <td>0.097762</td>\n",
       "      <td>0.361440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.247905</td>\n",
       "      <td>0.482714</td>\n",
       "      <td>0.291793</td>\n",
       "      <td>0.117786</td>\n",
       "      <td>0.777318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.597478</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.332472</td>\n",
       "      <td>0.582586</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.146643</td>\n",
       "      <td>0.878205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ages          sbp          dbp          bmi        tchol  \\\n",
       "count  2000.000000  2000.000000  2000.000000  1996.000000  2000.000000   \n",
       "mean      0.493845     0.371054     0.413667     0.270594     0.467650   \n",
       "std       0.148981     0.155093     0.146433     0.130686     0.150091   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.379982     0.258333     0.305556     0.184916     0.348271   \n",
       "50%       0.482143     0.366667     0.416667     0.247905     0.482714   \n",
       "75%       0.597478     0.458333     0.513889     0.332472     0.582586   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               hdl     glucosef    duration1  \n",
       "count  1997.000000  1905.000000  2000.000000  \n",
       "mean      0.313336     0.132905     0.638785  \n",
       "std       0.118098     0.074370     0.268002  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.227964     0.097762     0.361440  \n",
       "50%       0.291793     0.117786     0.777318  \n",
       "75%       0.379939     0.146643     0.878205  \n",
       "max       1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "test_size = 0.15\n",
    "train_X, train_Y, test_X, test_Y = model_selection.train_test_split\\\n",
    "(X,Y,test_size=test_size,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network with 4 layers\n",
    "#\n",
    "#       · · · ·                (input data, flattened pixels)          X [batch, 10] \n",
    "# \\x/x\\x/x\\x/x\\x/x\\x/ ✞      -- fully connected layer (relu+dropout)   W1 [10, 108]      B1[108]\n",
    "#  · · · · · · · · ·                                                   Y1 [batch, 108]\n",
    "#     \\x/x\\x/x\\x/ ✞          -- fully connected layer (relu+dropout)   W2 [108, 10]      B2[10]\n",
    "#       · · · ·                                                        Y2 [batch, 10]\n",
    "#         \\x/ ✞              -- fully connected layer (softmax)        W3 [10, 2]        B3[2]\n",
    "#          ·                                                           Y3 [batch, 2]\n",
    "X = tf.placeholder(\"float\",[None,10])\n",
    "Y_ = tf.placeholder(\"float\",[None,2])\n",
    "lr = tf.placeholder(tf.float32) # variable learning rate\n",
    "pkeep = tf.placeholder(tf.float32) # probability of keeping a node during dropout =1.0 at test,0.75 at training\n",
    "step = tf.placeholder(tf.int32) # step for variable learning rate\n",
    "tst = tf.placeholder(tf.bool)# train/test selector for batch normalisation\n",
    "iter = tf.placeholder(tf.int32)# training iteration\n",
    "\n",
    "# Three layers and their numbers of neurons(the last layer has 2 softmax neurons)\n",
    "L = 108\n",
    "M = 10\n",
    "# Weights initialised with small random values between -0.2 and +0.2, \n",
    "#Biases are initialised with small positive values( positive: because we are using Relu)\n",
    "W1 = tf.Variable(tf.truncated_normal([10,L],stddev=0.1))\n",
    "B1 = tf.Variable(tf.ones([L])/10)\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M],stddev=0.1))\n",
    "B2 = tf.Variable(tf.ones([M])/10)\n",
    "W3 = tf.Variable(tf.truncated_normal([M, 2],stddev=0.1))\n",
    "B3 = tf.Variable(tf.ones([2]))\n",
    "\n",
    "# The model, with dropout, batch normalization at each layer\n",
    "# batch norm scaling is not useful with relus\n",
    "# batch norm offsets are used instead of biases\n",
    "Y1l = tf.matmul(X, W1)\n",
    "Y1bn, update_ema1 = batchnorm(Y1l, tst, iter, B1)\n",
    "Y1r = tf.nn.relu(Y1bn)\n",
    "Y1 = tf.nn.dropout(Y1r, pkeep)\n",
    "\n",
    "Y2l = tf.matmul(Y1, W2)\n",
    "Y2bn, update_ema2 = batchnorm(Y2l,tst, iter, B2)\n",
    "Y2r = tf.nn.relu(Y2bn)\n",
    "Y2 = tf.nn.dropout(Y2r, pkeep)\n",
    "\n",
    "Ylogits = tf.matmul(Y2, W3) + B3\n",
    "Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "update_ema = tf.group(update_ema1, update_ema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cross-entropy loss function = -sum(Y_i*log(Yi)), normalised for batches of 100 images\n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability problems \n",
    "# with log(0) which is NaN\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "# accuracy of the trained model, between 0 and 1\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "import math\n",
    "# the learning rate is: # 0.0001 + 0.03 * (1/e)^(step/10000) i.e. exponential decay from 0.03->0.0001\n",
    "lr = 0.0001 + tf.train.exponential_decay(0.03, iter, 1000, 1/math.e)\n",
    "# training step\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhangle/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'next_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-db5685e3359e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'next_batch' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(20000):\n",
    "    batch_X, batch_Y = next_batch(100)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y_: batch_Y, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={X: batch_X, Y_: batch_Y, keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/zhangle/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets\")\n",
    "import mnist as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# matplotlib visualisation\n",
    "allweights = tf.concat([tf.reshape(W1, [-1]), tf.reshape(W2, [-1]), tf.reshape(W3, [-1])], 0)\n",
    "allbiases = tf.concat([tf.reshape(B1, [-1]), tf.reshape(B2, [-1]), tf.reshape(B3, [-1])], 0)\n",
    "# ti use for RELU\n",
    "allactivations = tf.concat([tf.reduce_max(Y1, [0]), tf.reduce_max(Y2, [0])], 0)\n",
    "alllogits = tf.concat([tf.reshape(Y1l, [-1]), tf.reshape(Y2l, [-1])], 0)\n",
    "# 有问题\n",
    "I = tensorflowvisu.tf_format_mnist_images(X, Y, Y_)\n",
    "It = tensorflowvisu.tf_format_mnist_images(X, Y, Y_, 1000, lines=25)\n",
    "datavis = tensorflowvisu.MnistDataVis(title4=\"Logits\", title5=\"Max activations across batch\", histogram4colornum=2, histogram5colornum=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_step(i, update_test_data, update_train_data):\n",
    "    # training on batches of 100 images with 100 labels\n",
    "    batch_X, batch_Y = next_batch(100)\n",
    "    \n",
    "    # compute training values for visualisation\n",
    "    if update_train_data:\n",
    "        a, c, im, al, ac, l = sess.run([accuracy, cross_entropy, I, alllogits, allactivations, lr],\n",
    "                                       feed_dict={X: batch_X, Y_: batch_Y, iter: i, tst: False})\n",
    "        print(str(i) + \": accuracy:\" + str(a) + \" loss: \" + str(c) + \" (lr:\" + str(l) + \")\")\n",
    "        datavis.append_training_curves_data(i, a, c)\n",
    "        datavis.update_image1(im)\n",
    "        datavis.append_data_histograms(i, al, ac)\n",
    "\n",
    "    # compute test values for visualisation\n",
    "    if update_test_data:\n",
    "        a, c, im = sess.run([accuracy, cross_entropy, It], {X: mnist.test.images, Y_: mnist.test.labels, tst: True})\n",
    "        print(str(i) + \": ********* epoch \" + str(i*100//mnist.train.images.shape[0]+1) + \" ********* test accuracy:\" + str(a) + \" test loss: \" + str(c))\n",
    "        datavis.append_test_curves_data(i, a, c)\n",
    "        datavis.update_image2(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the backpropagation training step\n",
    "sess.run([train_step, update_ema], feed_dict={X: batch_X, Y_: batch_Y, tst: False, iter: i})\n",
    "\n",
    "datavis.animate(training_step, iterations=10000+1, train_data_update_freq=20, test_data_update_freq=100, more_tests_at_start=True)\n",
    "\n",
    "# to save the animation as a movie, add save_movie=True as an argument to datavis.animate\n",
    "# to disable the visualisation use the following line instead of the datavis.animate line\n",
    "# for i in range(10000+1): training_step(i, i % 100 == 0, i % 20 == 0)\n",
    "\n",
    "print(\"max test accuracy: \" + str(datavis.get_max_test_accuracy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run([train_step, update_ema], feed_dict={X: batch_X, Y_: batch_Y, tst: False, iter: i})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
